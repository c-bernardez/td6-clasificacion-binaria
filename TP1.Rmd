---
title: "TP1: Clasificación binaria - Predicción de la comestibilidad de hongos"
author: "Micaela Oliva, Camila Bernardez"
# date: "`r Sys.Date()`"
output:
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Ejercicio 1: Introducción al problema

El dataset elegido tiene como origen:\

<https://www.kaggle.com/datasets/vishalpnaik/mushroom-classification-edible-or-poisonous?resource=download&select=mushroom.csv>


Es un dataset que busca clasificar si un hongo es comestible (edible) o no (poisonous). Para considerarlo, el dataset esta compuesto de 16 variables, de las cuáles:

- \texttt{class} (variable categórica binaria): indica si un hongo es comestible o no, y es lo que buscamos predecir.
    - edible 
    - poisonous


- \texttt{cap-diameter} (variable numérica): indica el diametro del sombrero del hongo en cm.


- \texttt{cap-shape} (variable categórica): indica el forma del sombrero del hongo.
    - 'bell' 
    - 'conical'
    - 'convex'
    - 'flat'
    - 'sunken'
    - 'spherical'
    - 'others'

  
- \texttt{cap-surface} (variable categórica): indica la textura de la superficie del sombrero del hongo.
    - 'fibrous' 
    - 'grooves' 
    - 'scaly'
    - 'smooth'
    - 'dry'
    - 'shiny'
    - 'leathery'
    - 'silky'
    - 'sticky'
    - 'wrinkled'
    - 'fleshy'
    - '' # 

    
- \texttt{cap-color} (variable categórica): indica el color del sombrero del hongo.
    - 'brown'
    - 'orange'
    - 'buff'
    - 'gray'
    - 'green'
    - 'pink'
    - 'purple'
    - 'red'
    - 'white'
    - 'yellow'
    - 'blue'
    - 'black'


- \texttt{does-bruise-or-bleed} (variable categórica binaria -> true/false): indica si el hongo al lesionarse presenta moratones o sangrado.
    - 'true'
    - 'false'


- \texttt{gill-attachment} (variable categórica): indica cómo las láminas del hongo se adhieren al pie.
    - 'adnate'
    - 'adnexed'
    - 'decurrent'
    - 'free'
    - 'sinuate'
    - 'pores'
    - 'none' #
    - '' #

    
- \texttt{gill-spacing} (variable categórica): indica la separación entre las láminas del hongo.
    - 'close'
    - 'distant'
    - 'none' #
    - '' #


- \texttt{stem-heigh} (variable numérica): indica la altura del pie del hongo en cm.


- \texttt{stem-width} (variable numérica): indica el ancho del pie del hongo en mm.



- \texttt{stem-root} (variable categórica): indica la estructura de la raíz del pie del hongo.
    - 'bulbous'
    - 'swollen'
    - 'club'
    - 'cup' #extra
    - 'equal' #extra
    - 'rhizomorphs'#extra
    - 'rooted' 
    - '' #falta es f, supongo que es none
    - '' #

- \texttt{veil-type} (variable categórica): indica el tipo de velo que cubre las láminas del hongo.
    - 'partial' #extra
    - 'universal'
    - '' #

- \texttt{has-ring} (variable categórica binaria -> true/false): indica si esta presente un anillo en el hongo o no.
    - 'true'
    - 'false'

- \texttt{ring-type} (variable categórica): indica el tipo del anillo presente en el hongo.
    - 'cobwebby' #extra 
    - 'evanescent'
    - 'flaring'
    - 'grooved'
    - 'large'
    - 'pendant'
    - 'sheathing', #extra
    - 'zone'
    - 'scaly' #extra
    - 'movable' 
    - 'none'
    - 'unknown' #extra
    - ''


- \texttt{habitat} (variable categórica): indica el ambiente en el cual el hongo fue encontrado.
    - 'grasses' 
    - 'leaves' 
    - 'meadows'
    - 'paths'
    - 'heaths'
    - 'urban'
    - 'waste'
    - 'woods'


- \texttt{season} (variable categórica): indica la estación en la cual el hongo es comunmente observado.
    - 'spring' 
    - 'summer'
    - 'autumn'
    - 'winter'


Para resumir, la variable class es una variable categórica binaria que indica si un hongo es comestible (edible) o venenoso (poisonous) pra poder hacer una clasificación binaria. 
Asimismo, el conjunto de datos tiene varias variables categóricas (cap-shape, cap-surface, cap-color, entre otras) y variables numéricas como cap-diameter, stem-heigh, y stem-width, cumpliendo así la inclusión de ambos tipos de atributos.
Las variables categóricas están representadas como palabras (e.g., cap-shape con valores como 'bell', 'conical', etc.). Además, hicimos un preprocesamiento de los datos tal que tengamos menos de 50.000 observaciones, pues el dataset original consistía de más de 60K de datos, y que además no tengan valores nulos.
Usamos árboles de decisión porque son capaces de manejar tanto variables categóricas como numéricas, permitiendo identificar de manera eficaz patrones complejos y no lineales en los datos. Además, los árboles de decisión pueden dividir los datos en función de múltiples atributos, 
lo que es útil cuando tenemos varias características relevantes, como en este caso, para clasificar hongos entre comestibles y venenosos.


## Ejercicio 2: Preparación de los datos


**Carga del conjunto de datos y realizamiento del preprocesamiento**

```{r}
mushrooms <- read.csv('mushrooms_small.csv')

table(is.na(mushrooms)) #verificamos que no hay valores nulos
nrow(mushrooms) #verificamos que hay menos de 50.000 observaciones
```

Como los datos ya se encuentran sampleados (menos de 50.000 observaciones) y sin valores null, para preprocesarlos encargaremos de:
  * cambiar los valores de las variables categóricas por palabras enteras en vez de letras.
  * quitar columnas que dependen de otras.

La fuente del dataset especifica que las columnas 'gill-color', 'stem-surface', 'stem-color', 'veil-color' y 'spore-print-color' dependen de 'cap-color' y 'cap-surface', así que decidimos eliminar estas columnas correlacionadas para disminuir al máximo posible el ruido, que podría distorsionar nuestra clasificación binaria.

```{r}
mushrooms <- mushrooms[, !(names(mushrooms) %in% c("gill.color", "stem.surface", "stem.color", "veil.color", "spore.print.color"))]
ncol(mushrooms)
```

Las variables categóricas toman valores de letras que pueden ser confusos, ya que no siempre reflejan de manera clara la palabra que representan (por ejemplo 'k' se utiliza en lugar de 'black'), y pueden repetirse entre columnas sin necesariamente significar lo mismo. Para que el manejo de los datos y las leyendas de los gráficos sean más claras decidimos reemplazarlas por las palabras correspondientes.

```{r, include='FALSE'}
#install.packages("dplyr")
library(dplyr)

mushrooms_renamed <- mushrooms %>%
  mutate(
    class = recode(class, 'e' = 'edible', 'p' = 'poisonous'),
    cap.shape = recode(cap.shape, 'b' = 'bell', 'c' = 'conical', 'x' = 'convex', 'f' = 'flat', 's' = 'sunken', 'p' = 'spherical', 'o' = 'others'),
    cap.surface = recode(cap.surface, 'i' = 'fibrous', 'f' = 'fibrous', 'g' = 'grooves', 'y' = 'scaly', 's' = 'smooth', 'd' = 'dry', 'h' = 'shiny', 'l' = 'leathery', 'k' = 'silky', 't' = 'sticky', 'w' = 'wrinkled', 'e' = 'fleshy',),
    cap.color = recode(cap.color, 'n' = 'brown', 'b' = 'buff', 'g' = 'gray', 'r' = 'green', 'p' = 'pink', 'u' = 'purple', 'e' = 'red', 'w' = 'white', 'y' = 'yellow', 'l' = 'blue', 'o' = 'orange', 'k' = 'black'),
    does.bruise.or.bleed = recode(does.bruise.or.bleed, 't' = 'true', 'f' = 'false'),
    gill.attachment = recode(gill.attachment, 'a' = 'adnate', 'x' = 'adnexed', 'd' = 'decurrent', 'e' = 'free', 's' = 'sinuate', 'p' = 'pores', 'f' = 'none', '?' = 'unknown'),
    gill.spacing = recode(gill.spacing, 'c' = 'close', 'd' = 'distant', 'f' = 'none'),
    stem.root = recode(stem.root, 'b' = 'bulbous', 's' = 'swollen', 'c' = 'club', 'u' = 'cup', 'e' = 'equal', 'z' = 'rhizomorphs', 'r' = 'rooted'),
    veil.type = recode(veil.type, 'p' = 'partial', 'u' = 'universal'),
    has.ring = recode(has.ring, 't' = 'true', 'f' = 'false'),
    ring.type = recode(ring.type, 'c' = 'cobwebby', 'e' = 'evanescent', 'r' = 'flaring', 'g' = 'grooved', 'l' = 'large', 'p' = 'pendant', 's' = 'sheathing', 'z' = 'zone', 'y' = 'scaly', 'm' = 'movable', 'f' = 'none', '?' = 'unknown'),
    habitat = recode(habitat, 'g' = 'grasses', 'l' = 'leaves', 'm' = 'meadows', 'p' = 'paths', 'h' = 'heaths', 'u' = 'urban', 'w' = 'waste', 'd' = 'woods'),
    season = recode(season, 's' = 'spring', 'u' = 'summer', 'a' = 'autumn', 'w' = 'winter')
  )
```

```{r}
head(mushrooms_renamed)
```


**Análisis exploratorio de datos: Estadísticas descriptivas y visualizaciones de las variables principales**

Inicialmente buscamos obtener estadísticas sencillas con el método $\texttt{summary}$, pero primero veamos de qué tipos de datos son nuestras variables. Encontramos solo dos tipos de datos en nuestro dataset: 3 variables de tipo $\texttt{numeric}$ **cap.diameter**, **stem.height** y **stem.width** y 13 categóricas de tipo $\texttt{character}$. Además, 3 de las 13 categóricas son binarias, incluyendo a nuestra variable a predecir **class**, que especifica si el hongo en cuestión es o no comestible ('edible' o 'poisonous').

```{r}
str(mushrooms_renamed)
```
Comenzamos por analizar la distribución de algunas variables. En primer lugar nos interesa análizar si tenemos una proporción más o menos pareja de los valores que toma **class**. Siendo que hay aproximadamente 44 observaciones de 'edible' para cada 55 observaciones de 'poisonous' nos aseguramos una buena distribución de valores para que el modelo tenga suficientes ejemplos de ambas clases para aprender y generalizar adecuadamente.

```{r}
num_edible <- sum(mushrooms_renamed$class == 'edible')
num_poisonous <- sum(mushrooms_renamed$class == 'poisonous')

prop_edible <- num_edible/(nrow(mushrooms_renamed))
prop_poisonous <- num_poisonous/(nrow(mushrooms_renamed))

print(paste("Edible:", num_edible, "(",round(prop_edible * 100, 2), "%)"))
print(paste("Poisonous:", num_poisonous, "(",round(prop_poisonous * 100, 2), "%)"))
```

MAS VARIABLES CATEGORICAS (histogramas?)

```{r}
selected_columns <- mushrooms_renamed[, c("cap.diameter", "stem.height", "stem.width")]
summary(selected_columns)
```
BOXPLOT?

Por último nos interesa analizar la correlación entre las variables, principalmente para saber si hay algunas variables más correlacionadas con nuestra variable objetivo que otras. Esto significaría que es posible que un modelo menos complejo (de menos variables) sea suficiente para predecirla.

```{r}
#install.packages("PerformanceAnalytics")
library("PerformanceAnalytics")

mushrooms_renamed[] <- lapply(mushrooms_renamed, function(x) if (is.character(x)) as.factor(x) else x)
mushrooms_numeric <- data.frame(lapply(mushrooms_renamed, function(x) if (is.factor(x)) as.numeric(x) else x))

#chart.Correlation(mushrooms_numeric, histogram=TRUE, pch=19)
```


## Ejercicio 3: Construcción de un árbol de decisión básico

```{r}
mushrooms_renamed$cap.shape <- as.factor(mushrooms_renamed$cap.shape)
mushrooms_renamed$cap.surface <- as.factor(mushrooms_renamed$cap.surface)
mushrooms_renamed$cap.color <- as.factor(mushrooms_renamed$cap.color)
mushrooms_renamed$gill.attachment <- as.factor(mushrooms_renamed$gill.attachment)
mushrooms_renamed$gill.spacing <- as.factor(mushrooms_renamed$gill.spacing)
mushrooms_renamed$stem.root <- as.factor(mushrooms_renamed$stem.root)
mushrooms_renamed$ring.type <- as.factor(mushrooms_renamed$ring.type)
mushrooms_renamed$veil.type <- as.factor(mushrooms_renamed$veil.type)
mushrooms_renamed$habitat <- as.factor(mushrooms_renamed$habitat)
mushrooms_renamed$season <- as.factor(mushrooms_renamed$season)

mushrooms_renamed$class <- as.factor(mushrooms_renamed$class)
mushrooms_renamed$does.bruise.or.bleed <- as.factor(mushrooms_renamed$does.bruise.or.bleed)
mushrooms_renamed$has.ring <- as.factor(mushrooms_renamed$has.ring)
```


```{r}
library(dplyr)
set.seed(42) #semilla para replicabilidad

n <- nrow(mushrooms_renamed)
indices <- sample(1:n) #'mezclamos' primero el orden de las filas, para luego solo tomar de la 1:70%, 70%-85% y 85%-100%
train_size <- floor(0.7 * n)
valid_size <- floor(0.15 * n)

train_indices <- indices[1:train_size]
valid_indices <- indices[(train_size + 1):(train_size + valid_size)]
test_indices <- indices[(train_size + valid_size + 1):n]

#creamos los subsets de datos
train_set <- mushrooms_renamed[train_indices, ]
valid_set <- mushrooms_renamed[valid_indices, ]
test_set <- mushrooms_renamed[test_indices, ]
```


```{r}
library(rpart)

tree_model <- rpart(class ~ ., 
                    data = train_set, 
                    method = "class")
```

```{r}
library(rpart.plot)

rpart.plot(tree_model)
```

## Ejercicio 4: Evaluación del árbol de decisión básico

**Matriz de confusión**

```{r}
# Instalacion y/o importe de las librerias
# install.packages('caret')
library(caret)
```

```{r}
# Predicciones de probabilidades y de clases
pred_prob <- predict(tree_model, test_set, type = "prob")  # Probabilidades predichas
pred_class <- predict(tree_model, test_set, type = "class")  # Clases predichas
```
Hacemos la Matriz de Confusión:
```{r}
conf_matrix <- confusionMatrix(pred_class, test_set$class)
print("Matriz de Confusión:")
print(conf_matrix$table)
print(t(conf_matrix$table)) # traspongo para que sea como visto en clase
```
Lo que obtenemos es:

* $TP = 2075$: Es un True Positive que dice la cantidad de instancias donde el modelo predijo \texttt{edible} y la clase verdaderamente valia edible.
* $FP = 613$: Es un False Positive que dice la cantidad de instancias donde el modelo predijo edible, pero la clase verdaderamente valia poisonous.
* $FN = 1008$: Es un False Negative que dice la cantidad de instancias donde el modelo predijo poisonous, pero la clase verdaderamente valia edible.
* $TN = 3215$: Es un True Negative que dice la cantidad de instancias donde el modelo predijo poisonous y la clase clase verdaderamente valia poisonous.

Por lo tanto, usamos Accuracy como una metrica de evaluacion si el resultado fue bueno:

**Accuracy**

Buscamos ver la proporcion de predicciones correctas (tanto positivas como negativas) de las predicciones totales.

$$Accuracy = \frac{TP + TN}{P + N} =$$ 
$$= \frac{TP + TN}{TP + FN + FP + TN} =$$
$$= \frac{TP + TN}{TP + FN + FP + TN} =$$
$$= \frac{2075 + 3215}{2075 + 1008 + 613 + 3215} =$$
$$= \frac{5290}{6911} = 0.7654464$$ 

En R:
```{r}
# 
TP <- conf_matrix$table[1, 1]
FP <- conf_matrix$table[1, 2]
FN <- conf_matrix$table[2, 1]
TN <- conf_matrix$table[2, 2]

# Calculamos el accuracy
Accuracy <- (TP + TN) / (TP + FN + FP + TN)
Accuracy

# Validacion
conf_matrix$overall['Accuracy']
```
Esto significa que el modelo clasifica correctamente alrededor de 76.5% de las instancias.

Lo que significa que en este caso $Error rate = 1 - Accuracy = 0.2345536$.

Pero para considerar que las clases pueden llegar a estar desbalanceadas, usaremos Precision-Recall:

**Precision and Recall**

- Precision: 

  Buscamos ver la proporcion de las instancias predichas de edible que verdaderamente valen edible.
  $$Precision_{edible} = \frac{TP}{TP + FP} =$$
  $$= \frac{2075}{2075 + 613} = 0.7719494$$

  En R:
  ```{r}
  Precision <- TP/(TP + FP)
  Precision

  # Validacion
  conf_matrix$byClass['Pos Pred Value']
  ```
  Esto significa que alrededor de 77.2% del tiempo cuando el modelo predice edible acierta.

- Recall: 

  Buscamos ver la proporcion de las instancias que verdaderamente valen edible que fueron correctamente predichas como edible.
  $$Recall_{edible} = \frac{TP}{TP + FN} =$$
  $$= \frac{2075}{2075 + 1008} = 0.6730457$$

  En R:
  ```{r}
  Recall <- TP/(TP + FN)
  Recall

  # Validacion
  conf_matrix$byClass['Sensitivity']
  ```

  Esto significa que alrededor de 67.3% el modelo identifica correctamente si los hongos son comestibles.
  
Pero, queremos una ponderacion conjunta de Precision y de Recall, por lo cual usaremos F1-Score.

**F1-Score**

$$F1-Score = \frac{2 * Precision * Recall}{Precision + Recall} =$$
$$= \frac{2 * 0.7719494 * 0.6730457}{0.7719494 + 0.6730457} = 0.7191128$$

En R:
```{r}
F1_score <- (2 * Precision * Recall)/(Precision + Recall)
F1_score
```

Esto significa que el accuracy del modelo en predicir la clase edible es igual a $0.7191128$.

**ROC-AUC Score**

Buscamos ver que tan bien el modelo tiene la capacidad de separar las clases. 

```{r}
library(pROC)

# Calculamos ROC curve
roc_curve <- roc(test_set$class, pred_prob[, "edible"])

#  AUC score
auc_value <- auc(roc_curve)
print(paste("AUC-ROC Score:", auc_value))

# Plot de ROC curve
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2)
```

$$AUC-ROC = 0.7921915$$

Esto significa que como $0.7921915 > 0.5$, el modelo se ejecuta mejor que hacer random guessing.